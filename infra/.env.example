# Naboo — Environment Configuration
# Copy to .env and fill in your values

# ── AWS IoT Core ──────────────────────────────────────────────
AWS_IOT_ENDPOINT=your-endpoint.iot.eu-west-2.amazonaws.com
AWS_REGION=eu-west-2
IOT_THING_NAME=naboo
IOT_CERT_PATH=/app/certs/device.cert.pem
IOT_KEY_PATH=/app/certs/device.private.key
IOT_CA_PATH=/app/certs/AmazonRootCA1.pem
IOT_CREDENTIALS_ENDPOINT=https://your-prefix.credentials.iot.eu-west-2.amazonaws.com
IOT_ROLE_ALIAS=your-role-alias

# ── Local LLM (Ollama on Mac mini) ───────────────────────────
OLLAMA_HOST=http://localhost:11434

# System 1 — fast local responses (~1-2s)
OLLAMA_MODEL_S1=qwen2.5:3b

# System 2 — smarter local responses (~5-6s)
# Note: qwen2.5:14b is too slow on 16GB (offloads to CPU); 7b is the sweet spot
OLLAMA_MODEL_S2=qwen2.5:7b

# ── Cloud LLM (AWS Bedrock) ───────────────────────────────────
BEDROCK_REGION=eu-west-2
BEDROCK_MODEL_ID=eu.anthropic.claude-haiku-4-5-20251001-v1:0
NABOO_MODEL_ID=anthropic.claude-sonnet-4-20250514-v1:0

# ── Robot (mBot2) ─────────────────────────────────────────────
MBOT2_WIFI_SSID=your_wifi_ssid
MBOT2_WIFI_PASSWORD=your_wifi_password
# MQTT broker — run on Mac mini (same machine as Ollama)
MQTT_BROKER=192.168.0.50
MQTT_PORT=1883

MBOT2_MQTT_BROKER=localhost
MBOT2_MQTT_PORT=1883

# ── Home Assistant ────────────────────────────────────────────
HA_URL=http://homeassistant.local:8123
HA_TOKEN=your_long_lived_access_token
CAMERA_ENTITY=camera.esp32_cam

# ── Optional ─────────────────────────────────────────────────
OPENWEATHER_API_KEY=
LOG_LEVEL=INFO

# Weather (PirateWeather — https://pirateweather.net)
PIRATEWEATHER_API_KEY=your_key_here

# MLX-LM inference (Apple Silicon — 3x faster than Ollama for 7b models)
# Leave blank to use Ollama instead
MLX_HOST=http://192.168.0.50:11435
MLX_MODEL_S1=mlx-community/Qwen2.5-3B-Instruct-4bit
MLX_MODEL_S2=mlx-community/Qwen2.5-7B-Instruct-4bit
